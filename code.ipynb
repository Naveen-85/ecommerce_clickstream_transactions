from matplotlib import pyplot as plt
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from scipy import sparse
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score
from sklearn.svm import SVC
from imblearn.over_sampling import SMOTE
from sklearn.ensemble import IsolationForest
import seaborn as sns
from imblearn.over_sampling import SMOTE
from sklearn.ensemble import IsolationForest

file_path = 'C:/Users/Admin/Desktop/ecommerce_clickstream_transactions.csv'
clickstream_data = pd.read_csv(file_path)

print(clickstream_data.dtypes)

numeric_features = ['Amount']  
categorical_features = ['EventType', 'ProductID', 'Outcome'] 

print(clickstream_data[numeric_features].dtypes)
print(clickstream_data[categorical_features].dtypes)
numerical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='mean')),
    ('scaler', StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)
    ]
)

try:
    X_preprocessed = preprocessor.fit_transform(clickstream_data)
    print("Preprocessed data shape:", X_preprocessed.shape)
except Exception as e:
    print("An error occurred during preprocessing:", e)

num_feature_names = numeric_features
cat_feature_names = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features)
all_feature_names = list(num_feature_names) + list(cat_feature_names)
print("All feature names:", all_feature_names)
print("Length of all feature names:", len(all_feature_names))
print("Shape of preprocessed data:", X_preprocessed.shape)

try:
    X_preprocessed_df = pd.DataFrame(X_preprocessed, columns=all_feature_names)
    print("x",X_preprocessed)
except ValueError as ve:
    print("ValueError:", ve)
    print("The number of columns in preprocessed data:", X_preprocessed.shape[1])
    print("The number of feature names provided:", len(all_feature_names))
try:
    if sparse.issparse(X_preprocessed):
        X_preprocessed = X_preprocessed.toarray()
    X_preprocessed_df = pd.DataFrame(X_preprocessed, columns=all_feature_names)
    print("Type of X_preprocessed:", type(X_preprocessed)) 
    print("Preprocessed DataFrame head:")
    print(X_preprocessed_df.head())
except ValueError as ve:
    print("ValueError:", ve)
    print("The number of columns in preprocessed data:", X_preprocessed.shape[1])
    print("The number of feature names provided:", len(all_feature_names))
for col in numeric_features:
    print(numeric_features)
    plt.figure(figsize=(8, 4))
    sns.histplot(X_preprocessed_df[col], kde=True)
    plt.title(f'Distribution of {col}')
    plt.xlabel(col)
    plt.ylabel('Frequency')
    plt.show()
for col in categorical_features:
    plt.figure(figsize=(10, 4))
    sns.countplot(data=clickstream_data, x=col)
    plt.title(f'Count of {col}')
    plt.xlabel(col)
    plt.ylabel('Count')
    plt.xticks(rotation=45)
    plt.show()
target_variable = clickstream_data ['Amount']
print(target_variable)
target_variable = clickstream_data['Outcome']

X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, target_variable, test_size=0.2, random_state=42, stratify=target_variable)

print("Training set class distribution:\n", y_train.value_counts(normalize=True))
print("Test set class distribution:\n", y_test.value_counts(normalize=True))
print("Training set class distribution:\n", y_train.value_counts(normalize=True))
print("Test set class distribution:\n", y_test.value_counts(normalize=True))


if len(np.unique(y_train)) > 1:
    smote = SMOTE(random_state=42)
    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)
    X_train = X_train_resampled
    y_train = y_train_resampled
    print("Resampled training set class distribution:\n", y_train_resampled.value_counts(normalize=True))
else:
    print("Skipping SMOTE as there's only one class in the training set.")

models = {
    'Random Forest': RandomForestClassifier(),
    'Logistic Regression': LogisticRegression(max_iter=1000),
    'Support Vector Machine': SVC()
}
for name, model in models.items():
    if len(np.unique(y_train)) > 1:
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        report = classification_report(y_test, y_pred)
        print(f"{name} Model:\n")
        print(f"Accuracy: {accuracy}\n")
        print(f"Classification Report:\n{report}\n")
    else:
        print(f"Skipping {name} as there's only one class in the training set.")


    
